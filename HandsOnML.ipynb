{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HandsOnML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPT6I7N074nCitTPtcrXvZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/js-june-moon/practice/blob/main/HandsOnML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmD1MDZguP2V"
      },
      "source": [
        "# Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\r\n",
        "## 한빛미디어 핸즈온 머신러닝(2판)의 내용을 정리한 colab 문서입니다.\r\n",
        "## 본 문서는 개인적인 학습을 위해서만 사용하며, github에 백업하여 관리하고 있습니다.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7JYje2dLKc0"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/js-june-moon/practice/main/cal_housing.data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tVNx2B-nEVI"
      },
      "source": [
        "# Chapter 1. 머신러닝\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjhEUaREnYpx"
      },
      "source": [
        "> 1.1 한눈에 보는 머신러닝\r\n",
        "\r\n",
        "    머신러닝이란?\r\n",
        "     - 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야\r\n",
        "     - 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, \r\n",
        "       이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.\r\n",
        "    \r\n",
        "    훈련세트(training set): 시스템이 학습하는 데 사용하는 샘플\r\n",
        "    훈련 사례(training instance, Sample): 각 훈련 데이터\r\n",
        "     * 예: 작업 T는 새로운 메일이 스팸인지 구분하는 것이고, 경험 E는 훈련 데이터, 성능 측정 P는 직접 정의해야 함\r\n",
        "    정확도(accuracy): 성능 측정   \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwokWbLNnYhS"
      },
      "source": [
        "> 1.2 왜 머신러닝을 사용하는가?\r\n",
        "\r\n",
        "    데이터 마이닝(data mining): 머신러닝 기술을 적용해서 대용량의 데이터를 분석하는 과정(이를 통해 겉으로는 보이지 않던 패턴을 발견할 수도 있음)\r\n",
        "    머신러닝이 뛰어난 분야(예시)\r\n",
        "     - 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제\r\n",
        "     - 전통적인 방식으로는 해결 방법이 없는 복잡한 문제\r\n",
        "     - 유동적인 환경\r\n",
        "     - 복잡한 문제와 대량의 데이터에서 통찰 얻기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSYfkQ4FnYab"
      },
      "source": [
        "> 1.3 애플리케이션 사례\r\n",
        "\r\n",
        "    이미지 자동 분석, 챗봇, 문서 요약, 음성 명령에 반응하는 앱 등 다양한 애플리케이션 사례 존재"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYvDGnA6nYQP"
      },
      "source": [
        "> 1.4 머신러닝 시스템의 종류\r\n",
        "\r\n",
        "**지도 학습과 비지도 학습**\r\n",
        "\r\n",
        "    지도 학습\r\n",
        "     - 지도 학습(supervised learning)에는 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함됨\r\n",
        "     - 머신러닝에서는 레이블의 범주를 클래스(class)라고 함\r\n",
        "     - 분류(classification)가 전형적인 지도 학습 작업임\r\n",
        "        예) 스팸 필터기\r\n",
        "     - 또 다른 전형적인 작업으로 예측 변수(predictor variable)이 있음\r\n",
        "        예) 특성(주행거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 타깃(target) 수치를 예측하는 것\r\n",
        "       -> 이런 종류의 작업을 회귀(regression)이라 함\r\n",
        "     - 머신러닝에서 속성(attribute)은 데이터 타입(예, 주행거리)이며,\r\n",
        "       특성은 문맥에 따라 여러 의미를 갖지만 일반적으로 속성과 값이 합쳐진 것(예, 주행거리 = 15,000)\r\n",
        "     - 회귀 문제: 주어진 입력 특성으로 값을 예측(일반적으로 입력 특성이 여러 개 있으며 이따금 값을 여러 개 출력하는 경우도 있음)\r\n",
        "     - 주요 지도 학습 알고리즘\r\n",
        "        * k-최근접 이웃(k-nearest neighbors)\r\n",
        "        * 선형 회귀(linear regression)\r\n",
        "        * 로지스틱 회귀(logistic regression): 클래스에 속할 확률을 출력함\r\n",
        "        * 서포트 벡터 머신(support vector machine, SVM)\r\n",
        "        * 결정 트리(decision tree), 랜덤 포레스트(random forest)\r\n",
        "        * 신경망(neural networks)\r\n",
        "\r\n",
        "    비지도 학습\r\n",
        "     - 비지도 학습(unsupervised learning)에는 말 그대로 훈련 데이터 레이블이 없음\r\n",
        "     - 시스템이 아무런 도움 없이 학습해야 함\r\n",
        "     - 주요 비지도 학습 알고리즘\r\n",
        "        * 군집(clustering)\r\n",
        "          - k-평균(k-means)\r\n",
        "          - DBSCAN\r\n",
        "          - 계층 군집 분석(hierarchical cluster analysis, HCA)\r\n",
        "          - 이상치 탐지(outlier detection), 특이치 탐지(novelty detection)\r\n",
        "          - 원-클래스(one-class SVM)\r\n",
        "          - 아이솔레이션 포레스트(isolation forest)\r\n",
        "        * 시각화(visualization), 차원 축소(dimensionality reduction)\r\n",
        "          - 주성분 분석(principal component analysis, PCA)\r\n",
        "          - 커널(kernel, PCA)\r\n",
        "          - 지역적 선형 임베딩(locally-linear embedding, LLE)\r\n",
        "          - t-SNE(t-distributed stochastic neighbor embedding)\r\n",
        "        * 연관 규칙 학습(association rule learning)\r\n",
        "          - 어프라이어리(apriori)\r\n",
        "          - 이클렛(eclat)\r\n",
        "     - 군집: 비슷한 데이터들을 그룹으로 묶는 것\r\n",
        "     - 시각화: 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어 줌\r\n",
        "     - 차원 축소: 너무 많은 정보를 잃지 않으면서 데이터를 간소화하는 것\r\n",
        "     - 특성 추출(feature extraction): 서로 다른 두 특성을 차의 마모 정도를 나타내는 하나의 특성으로 합치는 것(예시)\r\n",
        "     - 이상치 탐지: 학습 알고리즘에 주입하기 전에 데이터셋에 이상한 값을 자동으로 제거하는 것(예시)\r\n",
        "                    훈련 과정에서는 정상 샘플을 만나 이를 인식하도록 훈련\r\n",
        "     - 특이치 탐지: 훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적\r\n",
        "     - 연관 규칙 학습: 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 것\r\n",
        "\r\n",
        "    준지도 학습\r\n",
        "     - 데이터에 레이블을 다는 것은 일반적으로 시간과 비용이 많이 들기 때문에 레이블이 없는 샘플이 많고 레이블된 샘플은 적은 경우가 많음\r\n",
        "     - 어떤 알고리증믄 일부만 레이블이 있는 데이터를 다룰 수 있는데, 이를 준지도 학습(semisupervised learning)이라 함\r\n",
        "     - 대부분의 준지도 학습 알고리즘은 지도 학습 + 비지도 학습의 조합으로 이루어짐\r\n",
        "        예) 심층 신뢰 신경망(deep belief network, DBN)은 여러 겹으로 쌓은 제한된 볼츠만 머신(Boltzmann machine, RBM)이라 불리는 비지도 학습에 기초\r\n",
        "    \r\n",
        "    강화 학습\r\n",
        "     - 학습하는 시스템을 에이전트라 부르며 환경(environment)을 관찰해서 행동(action)을 실행하고 \r\n",
        "       그 결과로 보상(reward, 또는 부정적인 보상(penalty))을 받음\r\n",
        "     - 시간이 지나면서 가장 큰 보상을 얻기 위해 정책(policy)이라 불리는 최상의 전략을 스스로 학습\r\n",
        "     - 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의\r\n",
        "\r\n",
        "**배치 학습과 온라인 학습**\r\n",
        "\r\n",
        "    머신러닝 시스템을 분류하는 데 사용하는 다른 기준은 입력 데이터의 스트림(stream)부터 점진적으로 학습할 수 있는지의 여부\r\n",
        "\r\n",
        "    배치 학습(batch learning)\r\n",
        "     - 배치 학습에서는 시스템이 점진적으로 학습할 수 없음\r\n",
        "     - 가용한 데이터를 모두 사용해 훈련시켜야 함\r\n",
        "     - 일반적으로 이 방식은 시간과 자원을 많이 소모해 보통 오프라인에서 수행\r\n",
        "     - 먼저 시스템을 훈련시키고 그런 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행\r\n",
        "     - 학습한 것을 단지 적용만 하며, 이를 오프라인 학습(offline learning)이라 함\r\n",
        "     - 배치 학습 시스템이 새로운 데이터에 대해 학습하려면 전체 데이터를 사용해 시스템의 새로운 버전을 처음부터 다시 훈련해야 함\r\n",
        "    \r\n",
        "    온라인 학습(online learning)\r\n",
        "     - 온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 미니배치(mini-batch)라 부르는 작은 묶음 단우로 주입해 시스템을 훈련시킴\r\n",
        "     - 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있음\r\n",
        "     - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합\r\n",
        "     - 외부 메모리 학습(out-of-core learning)\r\n",
        "       * 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에 온라인 학습 알고리즘을 사용할 수 있으며,\r\n",
        "         이를 외부 메모리 학습이라 함\r\n",
        "       * 외부 메모리 학습은 보통 오프라인으로 실행\r\n",
        "       * 즉, 실시간 시스템에서 수행되는 것이 아님\r\n",
        "       * 따라서 이를 점진적 학습(incremental learning)이라 생각하는 것이 편함\r\n",
        "     - 학습률(learning rate): 변화하는 데이터에 얼마나 빠르게 적응할 것인지에 대한 온라인 학습 시스템에서의 중요한 파라미터 중 하나\r\n",
        "       * 학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버릴 것\r\n",
        "       * 반대로 학습률이 낮으면 시스템의 관성이 더 커져 더 느리게 학습\r\n",
        "       * 하지만 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐\r\n",
        "\r\n",
        "**사례 기반 학습과 모델 기반 학습**\r\n",
        "\r\n",
        "    사례 기반 학습(instance-based learning)\r\n",
        "     - 시스템이 훈련 샘플을 기억함으로써 학습함\r\n",
        "     - 그리고 유사도(similarity) 측정(measure)을 사용해 새로운 데이터와 학습한 샘플을(또는 학습한 샘플 중 일부를) 비교하는 식으로 일반화\r\n",
        "\r\n",
        "    모델 기반 학습(model-based learning)\r\n",
        "     - 샘플로부터 일반화시키는 다른 방법은 이 샘플들의 모델을 만들어 예측(prediction)에 사용하는 것\r\n",
        "     - 모델 선택(model selection), 선형 모델(linear model), 모델 파라미터(model parameter)\r\n",
        "     - 모델 파라미터를 조정하여 어떤 선형 함수를 표현하는 모델을 얻을 수 있음\r\n",
        "     - 모델이 최상의 성능을 내도록 하는 값을 알기 위해 측정 지표를 정해야 함\r\n",
        "     - 모델이 얼마나 좋은지 측정하는 효용 함수(utility function, 또는 적합도 함수(fitness function))를 정의하거나\r\n",
        "       모델이 얼마나 나쁜지 측정하는 비용 함수(cost function)를 정의할 수 있음\r\n",
        "     - 선형 회귀에서는 보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용 함수를 사용하며, 이 거리를 최소화하는 것이 목표\r\n",
        "     - 선형 회귀 알고리즘(linear regression algorithm)\r\n",
        "      * 알고리즘에 훈련 데이터를 공급하면 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾음\r\n",
        "      * 이를 모델을 훈련(training)시킨다고 함\r\n",
        "\r\n",
        "**지금까지의 작업 요약**\r\n",
        "\r\n",
        "    * 데이터를 분석합니다.\r\n",
        "    * 모델을 선택합니다.\r\n",
        "    * 훈련 데이터로 모델을 훈련시킵니다.(즉, 학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾습니다.)\r\n",
        "    * 마지막으로 새로운 데이터에 모델을 적용해 예측을 하고(이를 추론(inference)이라고 합니다.), 이 모델이 잘 일반화되길 기대합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhBU7YhInYG_"
      },
      "source": [
        "> 1.5 머신러닝의 주요 도전 과제\r\n",
        "\r\n",
        "* 나쁜 데이터의 사례\r\n",
        "  * 충분하지 않은 양의 훈련 데이터\r\n",
        "  * 대표성이 없는 훈련 데이터\r\n",
        "  * 낮은 품질의 데이터\r\n",
        "  * 관련 없는 특성\r\n",
        "\r\n",
        "\r\n",
        "      * 대표성이 없는 훈련 데이터\r\n",
        "\r\n",
        "    일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 매우 중요하지만, 이게 생각보다 어려울 때가 많음\r\n",
        "    샘플이 작으면 샘플링 잡음(sampling noise, 우연에 의한 대표성 없는 데이터)이 생기고,\r\n",
        "    매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못할 수 있으며 이를 샘플링 편향(sampling bias)이라 함\r\n",
        "\r\n",
        "      * 관련 없는 특성\r\n",
        "\r\n",
        "    특성 공학(feature engineering)\r\n",
        "     - 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것\r\n",
        "     - 이 과정을 특성 공학이라 하며 다음과 같은 작업 진행\r\n",
        "       * 특성 선택(feature selection): 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택\r\n",
        "       * 특성 추출(feature extraction): 특성을 결합하여 더 유용한 특성을 만듦\r\n",
        "                                        앞서 본 것처럼 차원 축소 알고리즘이 도움될 수 있음\r\n",
        "       * 새로운 데이터를 수집해 새 특성을 만듦\r\n",
        "\r\n",
        "* 나쁜 알고리즘의 사례\r\n",
        "  * 훈련 데이터 과대적합\r\n",
        "  * 훈련 데이터 과소적합\r\n",
        "\r\n",
        "\r\n",
        "      * 훈련 데이터 과대적합\r\n",
        "\r\n",
        "    과대적합(overfiting)\r\n",
        "     - 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어진다는 것\r\n",
        "     - 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 일어남\r\n",
        "     - 해결 방법은 다음과 같음\r\n",
        "       * 파라미터 수가 적은 모델을 선택하거나(예, 고차워 다항 모델보다 선형 모델), \r\n",
        "         훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화시키기\r\n",
        "       * 훈련 데이터를 더 많이 모으기\r\n",
        "       * 훈련 데이터의 잡음 줄이기(예, 오류 데이터 수정과 이상치 제거)\r\n",
        "     - 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 규제(regularization)이라 함\r\n",
        "     - 훈련 데이터에 모델을 맞추기 위한 자유도(degree of freedom)를 학습 알고리즘에 부여하는 파라미터\r\n",
        "     - 학습하는 동안 적용할 규제의 양은 하이퍼파라미터(hyperparameter)가 결정\r\n",
        "     - 하이퍼파라미터는 (모델이 아니라) 학습 알고리즘의 파라미터임\r\n",
        "     - 그래서 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에는 상수로 남아 있음\r\n",
        "     - 규제 하이퍼파라미터를 매우 큰 값으로 지정하면(기울기가 0에 가까운) 거의 평편한 모델을 얻음\r\n",
        "     - 그러면 학습 알고리즘이 훈련 데이터에 과대적합될 가능성은 거의 없겠지만 좋은 모델을 찾지 못함\r\n",
        "     - 머신러닝 시스템을 구축할 때 하이퍼파라미터 튜닝은 매우 중요한 과정\r\n",
        "\r\n",
        "      * 훈련 데이터 과소적합\r\n",
        "\r\n",
        "    과소적합(underfiting)\r\n",
        "     - 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어남\r\n",
        "     - 이 문제를 해결하는 주요 기법\r\n",
        "       * 모델 파라미터가 더 많은 강력한 모델을 선택\r\n",
        "       * 학습 알고리즘에 더 좋은 특성 제공(특성 공학)\r\n",
        "       * 모델의 제약 줄이기(예, 규제 하이퍼파라미터 감소)\r\n",
        "\r\n",
        "**내용 정리**\r\n",
        "\r\n",
        "* 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것\r\n",
        "* 여러 종류의 머신러닝 시스템 존재(지도 학습, 비지도 학습, 배치 학습, 온라인 학습, 사례기반 학습, 모델 기반 학습 등)\r\n",
        "* 머신러닝 프로젝트에서는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입\r\n",
        "  * 학습 알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하고(즉, 훈련 세트에서 좋은 예측을 만들기 위해), 새로운 데이터에서도 좋은 예측을 만들 거라 기대\r\n",
        "  * 학습 알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 유사도 측정을 사용하여 학습한 샘플과 새로운 샘플을 비교하는 식으로 새로운 샘플에 일반화함\r\n",
        "* 훈련 세트가 너무 작거나, 대표성이 없는 데이터이거나, 잡음이 많고 관련 없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않음\r\n",
        "* 모델이 너무 단순하거나(과소적합된 경우) 너무 복잡하지 않아야 함(과대적합된 경우)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHe48RcenX88"
      },
      "source": [
        "> 1.6 테스트와 검증\r\n",
        "\r\n",
        "테스트\r\n",
        "\r\n",
        "    훈련 데이터를 훈련 세트와 테스트 세트로 나눠 테스트를 진행하는 것이 나은 방법\r\n",
        "     - 훈련 세트를 사용해 모델을 훈련하고 테스트 세트를 사용해 모델을 테스트\r\n",
        "     - 새로운 샘플에 대한 오류 비율을 일반화 오차(generalization error, 또는 외부 샘플 오차(out-of-sample error))라 하며, \r\n",
        "       테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값(estimation)을 얻음\r\n",
        "\r\n",
        "    홀드아웃 검증(holdout validation)\r\n",
        "     - 간단하게 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택\r\n",
        "     - 이 새로운 홀드아웃 세트를 검증 세트(validation set)라 부름(개발세트(development set), 데브 세트(dev set) 라고도 함)\r\n",
        "     - 구체적으로 줄어든 훈련 세트(전체 훈련 세트 - 검증 세트 인 데이터)에서 다양한 하이퍼파라미터 값을 가진 여러 모델 훈련\r\n",
        "     - 그 다음 검증 세트에서 가장 높은 성능을 내는 모델 선택\r\n",
        "     - 홀드아웃 검증 과정 끝나면 이 최선의 모델을(검증 세트를 포함한) 전체 훈련 세트에서 다시 훈련하여 최종 모델 만듦\r\n",
        "     - 마지막으로 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정\r\n",
        "\r\n",
        "    교차 검증(cross-validation)\r\n",
        "     - 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가\r\n",
        "     - 모든 모델의 평가를 평균하면 훨씬 정확한 성능을 측정할 수 있음\r\n",
        "     - 단점으로는, 휸련 시간이 검증 세트의 개수에 비례해 늘어남\r\n",
        "    \r\n",
        "    훈련-개발 세트(train-dev set)\r\n",
        "     - 훈련 사진의 일부를 떼어내어 또 다른 세트를 만드는 것"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdxfeWTRLPWs"
      },
      "source": [
        "# Chapter 2. 머신러닝 프로젝트 처음부터 끝까지\r\n",
        "---\r\n",
        "**주요 단계**\r\n",
        "\r\n",
        "    1.   큰 그림을 봅니다.\r\n",
        "    2.   데이터를 구합니다.\r\n",
        "    3.   데이터로부터 통찰을 어기 위해 탐색하고 시각화합니다.\r\n",
        "    4.   머신러닝 알고리즘을 위해 데이터를 준비합니다.\r\n",
        "    5.   모델을 선택하고 훈련시킵니다.\r\n",
        "    6.   모델을 상세하게 조정합니다.\r\n",
        "    7.   솔루션을 제시합니다.\r\n",
        "    8.   시스템을 론칭하고 모니터링하고 유지 보수합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvCU-viLNFYP"
      },
      "source": [
        ">2.1 실제 데이터로 작업하기\r\n",
        "\r\n",
        "    *   유명한 공개 데이터 저장소\r\n",
        "      -   UC 얼바인 머신러닝 저장소(http://archive.ics.uci.deu/ml)\r\n",
        "      -   캐글 데이터셋(http://www.kaggle.com/datasets)\r\n",
        "      -   아마존 AWS 데이터셋(https://registry.opendata.aws)\r\n",
        "    *   메타 포털\r\n",
        "      -   데이터 포털(http://dataportals.org)\r\n",
        "      -   오픈 데이터 모니터(http://opendatamonitor.eu)\r\n",
        "      -   퀀들(http://quandl.com)\r\n",
        "    *   인기 있는 공개 데이터 저장소가 나열되어 있는 다른 페이지\r\n",
        "      -   위키백과 머신러닝 데이터셋 목록(https://goo.gl/SJHN2k)\r\n",
        "      -   Quora.com(https://homl.info/10)\r\n",
        "      -   데이터셋 서브레딧(http://www.reddit.com/r/datasets)\r\n",
        "\r\n",
        "**StatLib 저장소에 있는 캘리포니아 주택 가격 데이터셋 사용**\r\n",
        "\r\n",
        "      StatLib 저장소(http://lib.stat.cmu.edu/datasets/)\r\n",
        "\r\n",
        "      본 장에서는 수정된 버전을 사용하며 해당 버전은 아래의 링크에 존재\r\n",
        "\r\n",
        "      https://goo.gl/QgRbUL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cct4KebnSBpm"
      },
      "source": [
        ">2.2 큰 그림 보기\r\n",
        "\r\n",
        "**필기**\r\n",
        "    \r\n",
        "    1. 문제정의\r\n",
        "     머신러닝 시스템에 주입하는 정보를 클로드 섀넌의 정보 이론을 따라 종종 신호(signal)이라 함\r\n",
        "     데이터 처리 컴포넌트들이 연속되어 있는 것을 데이터 파이프라인이라 함\r\n",
        "\r\n",
        "     문제 정의\r\n",
        "      1. 비즈니스의 목적이 정확히 무엇인가요?\r\n",
        "      2. 현재 솔루션은 어떻게 구성되어 있나요? \r\n",
        "\r\n",
        "    2. 성능 측정 지표 선택\r\n",
        "     회귀 문제의 전형적인 성능 지표는 평균 제곱근 오차\r\n",
        "     RMSE(Root Mean Square Error)\r\n",
        "      -> 오차가 커질수록 이 값은 더욱 커지므로 예측에 얼마나 많은 오류가 있는지 가늠하게 해줌\r\n",
        "     표기법\r\n",
        "      m = RMSE를 측정할 데이터셋에 있는 샘플 수\r\n",
        "      x(i) = 데이터셋에 있는 i번째 샘플(레이블은 제외한)의 전체 특성값의 벡터\r\n",
        "      y(i) = 해당 레이블(해당 샘플의 기대 출력값)\r\n",
        "      X = 데이터셋에 있는 모든 샘플의 모든 특성값(레이블은 제외)을 포함하는 행렬\r\n",
        "          샘플 하나가 하나의 행이어서 i번째 해은 x(i)의 전치와 같고 (x(i))^T로 표기\r\n",
        "      h = 시스템의 예측 함수이며 가설(hypothesis)\r\n",
        "      시스템이 하나의 샘플 특성 벡터 x(i)를 받으면 그 샘플에 대한 예측값 y_hat(i) = h(x(i)) 출력\r\n",
        "      RMSE(X, h)는 가설 h를 사용하여 일련의 샘플을 평가하는 비용 함수\r\n",
        "\r\n",
        "     이상치로 많이 보이는 구역에서는 평균 절대 오차(평균 절대 편차) 고려해볼 수 있음\r\n",
        "     Mean Absolute Error, Mean Absolute Deviation\r\n",
        "\r\n",
        "     RMSE와 MAE 모두 예측값의 벡터와 타깃값의 벡터 사이의 거리를 재는 방법\r\n",
        "\r\n",
        "    3. 가정 검사"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggB0Rp58LRlF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}